{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import trange\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# 数据读取\n",
    "train = pd.read_csv('./data/train_stage2_update_20200320.csv')\n",
    "train_y = pd.read_csv('./data/train_label.csv').Label\n",
    "test = pd.read_csv('./data/test_stage2_update_20200320.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 经EDA发现训练集中部分特征分布情况与测试集不一致\n",
    "# 将这部分数据的训练权重设置为0.01，降低这部分分布不一致数据对模型训练的影响\n",
    "# 在提高模型训练效果的同时，避免对训练集过拟合\n",
    "# 不直接删除这部分数据，保留了对这部分数据的学习，降低了它们的影响，提高模型泛化能力\n",
    "train['weight'] = 1\n",
    "test['weight'] = 1\n",
    " \n",
    "train.loc[train['流动资产合计_年末数']<0, 'weight'] = 0.01\n",
    "train.loc[train['其他应收款_年初数']<0, 'weight'] = 0.01\n",
    "train.loc[train['流动资产合计_年初数']<0, 'weight'] = 0.01\n",
    "train.loc[train['其他应收款_年末数']<0, 'weight'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将EDA发现的部分离群值设置为None，避免异常信息影响模型学习，降低过拟合\n",
    "train.loc[train['注册资本']>10000, '注册资本'] = None\n",
    "train.loc[train['其他应收款_年末数']>400000, '其他应收款_年末数'] = None\n",
    "train.loc[train['其他应收款_年末数']>400000, '其他应收款_年末数'] = None\n",
    "train.loc[train['流动资产合计_年末数']<0, '流动资产合计_年末数'] = None\n",
    "train.loc[train['其他应收款_年初数']<0, '其他应收款_年初数'] = None\n",
    "train.loc[train['流动资产合计_年初数']<0, '流动资产合计_年初数'] = None\n",
    "train.loc[train['其他应收款_年末数']<0, '其他应收款_年末数'] = None\n",
    "\n",
    "test.loc[test['企业所得税']>7000, '企业所得税'] = None\n",
    "test.loc[test['城建税']>300, '城建税'] = None\n",
    "test.loc[test['增值税']>5000, '增值税'] = None\n",
    "test.loc[test['教育费']>140, '教育费'] = None\n",
    "\n",
    "data = train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征名称，综合考虑特征重要性和特征缺失程度，确定所使用的原始特征\n",
    "feat_imp = ['企业所得税','城建税','增值税','印花税','教育费','年度参保总额',\n",
    "            '货币资金_年末数','行业代码','最新参保人数','注册资本','货币资金_年初数',\n",
    "            '投资总额','行业门类','企业类型','其他应收款_年末数','登记注册类型代码',\n",
    "            '登记机关','资本变更前','流动资产合计_年初数','其他应收款_年初数','流动资产合计_年末数',\n",
    "            '管辖机关','固定资产合计_年初数','未分配利润_年末数','非流动资产合计_年初数']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 税务特征\n",
    "data[\"经营范围\"] = data[\"经营范围\"].apply(lambda x: x.count(\",\") + 1)\n",
    "data[\"是否全资\"] = data['注册资本'] >= data['投资总额']\n",
    "data[\"企业缴税\"] = np.sum(data[['增值税', '企业所得税', '印花税', '城建税', \"教育费\"]], axis=1)\n",
    "data[\"增值税/企业缴税\"] = data[\"增值税\"] / data[\"企业缴税\"]\n",
    "data[\"企业所得税/企业缴税\"] = data[\"企业所得税\"] / data[\"企业缴税\"]\n",
    "data[\"印花税/企业缴税\"] = data[\"印花税\"] / data[\"企业缴税\"]\n",
    "data[\"教育费/企业缴税\"] = data[\"教育费\"] / data[\"企业缴税\"]\n",
    "data[\"城建税/企业缴税\"] = data[\"城建税\"] / data[\"企业缴税\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 业务特征 年初年末变化\n",
    "data['年度参保总额/企业缴税'] = data['年度参保总额']/data[\"企业缴税\"]\n",
    "data['企业缴税/经营范围'] = data[\"企业缴税\"]/data['经营范围']\n",
    "data['投资总额/企业缴税'] = data['投资总额']/data[\"企业缴税\"]\n",
    "\n",
    "data['货币资金变化'] = data['货币资金_年末数']-data['货币资金_年初数']\n",
    "data['流动资产合计变化'] = data['流动资产合计_年末数'] - data['流动资产合计_年初数']\n",
    "data['其他应收款变化'] = data['其他应收款_年末数'] - data['其他应收款_年初数']\n",
    "data['固定资产合计变化'] = data['固定资产合计_年末数'] - data['固定资产合计_年初数']\n",
    "data['未分配利润变化'] = data['未分配利润_年末数'] - data['未分配利润_年初数']\n",
    "data['非流动资产合计变化'] = data['非流动资产合计_年末数'] - data['非流动资产合计_年初数']\n",
    "data['短期借款变化'] = data['短期借款_年末数'] - data['短期借款_年初数']\n",
    "data['应交税费变化'] = data['应交税费_年末数'] - data['应交税费_年初数']\n",
    "data['负债合计变化'] = data['负债合计_年末数'] - data['负债合计_年初数']\n",
    "data['其他应付款变化'] = data['其他应付款_年末数'] - data['其他应付款_年初数']\n",
    "data['负债和所有者权益总计变化'] = data['负债和所有者权益总计_年末数'] - data['负债和所有者权益总计_年初数']\n",
    "data['所有者权益合计变化'] = data['所有者权益合计_年末数'] - data['所有者权益合计_年初数']\n",
    "data['其他流动负债变化'] = data['其他流动负债_年末数'] - data['其他流动负债_年初数']\n",
    "data['流动负债合计变化'] = data['流动负债合计_年末数'] - data['流动负债合计_年初数']\n",
    "data['存货变化'] = data['存货_年末数'] - data['存货_年初数']\n",
    "data['资产总计变化'] = data['资产总计_年末数'] - data['资产总计_年初数']\n",
    "data['预收款项变化'] = data['预收款项_年末数'] - data['预收款项_年初数']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count特征，在数据的value_counts分布有一定规律时，会更有效\n",
    "for col in feat_imp:\n",
    "    data[f'{col}_catcount'] = data[col].map(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  4%|███▎                                                                               | 1/25 [00:03<01:16,  3.19s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  8%|██████▋                                                                            | 2/25 [00:06<01:10,  3.08s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 12%|█████████▉                                                                         | 3/25 [00:08<01:06,  3.03s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 16%|█████████████▎                                                                     | 4/25 [00:11<01:03,  3.02s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 20%|████████████████▌                                                                  | 5/25 [00:14<00:58,  2.94s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 24%|███████████████████▉                                                               | 6/25 [00:17<00:54,  2.85s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 28%|███████████████████████▏                                                           | 7/25 [00:19<00:49,  2.74s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 32%|██████████████████████████▌                                                        | 8/25 [00:22<00:45,  2.68s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 36%|█████████████████████████████▉                                                     | 9/25 [00:24<00:41,  2.59s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▊                                                 | 10/25 [00:27<00:37,  2.50s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 44%|████████████████████████████████████                                              | 11/25 [00:29<00:33,  2.37s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 48%|███████████████████████████████████████▎                                          | 12/25 [00:31<00:30,  2.38s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 52%|██████████████████████████████████████████▋                                       | 13/25 [00:33<00:28,  2.39s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 56%|█████████████████████████████████████████████▉                                    | 14/25 [00:35<00:24,  2.23s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 60%|█████████████████████████████████████████████████▏                                | 15/25 [00:37<00:20,  2.06s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 64%|████████████████████████████████████████████████████▍                             | 16/25 [00:39<00:17,  1.99s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 68%|███████████████████████████████████████████████████████▊                          | 17/25 [00:40<00:15,  1.91s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 72%|███████████████████████████████████████████████████████████                       | 18/25 [00:42<00:12,  1.75s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 76%|██████████████████████████████████████████████████████████████▎                   | 19/25 [00:43<00:10,  1.70s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████▌                | 20/25 [00:45<00:08,  1.66s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 84%|████████████████████████████████████████████████████████████████████▉             | 21/25 [00:47<00:06,  1.71s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 22/25 [00:48<00:05,  1.67s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 92%|███████████████████████████████████████████████████████████████████████████▍      | 23/25 [00:50<00:03,  1.56s/it]C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:52<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 交叉特征，直接进行原始特征的交叉，同时借助lgb特征重要性进行筛选\n",
    "train = data[:train.shape[0]]\n",
    "test = data[train.shape[0]:]\n",
    "\n",
    "d={'add':'+', 'sub':'-', 'mul':'*', 'div':'/'}\n",
    "feat0 = feat_imp.copy()\n",
    "feat_cross = []\n",
    "for i in trange(len(feat_imp)):\n",
    "    df_temp=train[feat_imp].copy()\n",
    "    for j in range(i+1,len(feat_imp)):\n",
    "        df_temp['%s|%s|add'%(feat_imp[i],feat_imp[j])] = train[feat_imp[i]]+train[feat_imp[j]]\n",
    "        df_temp['%s|%s|sub'%(feat_imp[i],feat_imp[j])] = train[feat_imp[i]]-train[feat_imp[j]]\n",
    "        df_temp['%s|%s|mul'%(feat_imp[i],feat_imp[j])] = train[feat_imp[i]]*train[feat_imp[j]]\n",
    "        df_temp['%s|%s|div'%(feat_imp[i],feat_imp[j])] = train[feat_imp[i]]/train[feat_imp[j]]\n",
    "    model = LGBMClassifier(n_estimators=200, learning_rate=0.2, max_depth=7, \n",
    "                           subsample=0.8, colsample_bytree=0.6, n_jobs=-1)\n",
    "    model.fit(df_temp.values, train_y)\n",
    "    qq = pd.Series(model.feature_importances_, index=df_temp.columns).sort_values()\n",
    "    for col in set(qq.loc[qq>10].index)-set(feat0):\n",
    "        f0, f1, f2 = col.split('|')\n",
    "        train[col] = df_temp[col]\n",
    "        test[col] = eval(\"test['%s']%stest['%s']\"%(f0,d[f2],f1))\n",
    "    feat_cross.extend(list(set(qq.loc[qq>10].index)-set(feat0)))\n",
    "print(len(feat_cross))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\n",
      "831\n"
     ]
    }
   ],
   "source": [
    "# 特征选择，结合特征类别、特征nunique和缺失程度进行筛选\n",
    "data = train.append(test)\n",
    "feat = list(set(data.columns)-set(data.select_dtypes(object))-set(['Label','ID','weight']))\n",
    "remove_col = []\n",
    "for col in feat:\n",
    "    if (data[col].nunique() < 2) or (data[col].isnull().sum()/data.shape[0] > 0.95):\n",
    "        remove_col.append(col)\n",
    "print(len(remove_col))\n",
    "feat0 = list(set(feat) - set(remove_col))\n",
    "print(len(feat0))\n",
    "\n",
    "data = data[feat0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.13459\n",
      "[400]\tvalid_0's binary_logloss: 0.12864\n",
      "Early stopping, best iteration is:\n",
      "[496]\tvalid_0's binary_logloss: 0.12823\n",
      "1_training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.14441\n",
      "[400]\tvalid_0's binary_logloss: 0.140411\n",
      "Early stopping, best iteration is:\n",
      "[381]\tvalid_0's binary_logloss: 0.140331\n",
      "2_training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.151429\n",
      "Early stopping, best iteration is:\n",
      "[269]\tvalid_0's binary_logloss: 0.149779\n",
      "3_training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.139882\n",
      "[400]\tvalid_0's binary_logloss: 0.134372\n",
      "[600]\tvalid_0's binary_logloss: 0.133718\n",
      "Early stopping, best iteration is:\n",
      "[558]\tvalid_0's binary_logloss: 0.133571\n",
      "4_training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.147033\n",
      "[400]\tvalid_0's binary_logloss: 0.143688\n",
      "Early stopping, best iteration is:\n",
      "[354]\tvalid_0's binary_logloss: 0.143409\n",
      "score: 0.13906423712065238 [0.12823024738958894, 0.14033148208803134, 0.14977934201503385, 0.13357105220039162, 0.14340906191021613]\n"
     ]
    }
   ],
   "source": [
    "# 使用lightgbm初训练获取预测结果用于后续stacking\n",
    "kf = StratifiedKFold(5,True,random_state=1)\n",
    "prob = np.zeros(len(train))\n",
    "test_prob = np.zeros(len(test))\n",
    "test_data = test[feat0].values\n",
    "valid_score = []\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(train, train_y)):\n",
    "    print(str(idx) + '_training')\n",
    "    train_data = train.loc[train_index][feat0].values\n",
    "    valid_data = train.loc[valid_index][feat0].values\n",
    "    model = LGBMClassifier(n_estimators=1000, learning_rate=0.01, num_leaves=15, \n",
    "                           subsample=0.8, colsample_bytree=0.6, n_jobs=4)\n",
    "    model.fit(train_data, train_y.loc[train_index], \n",
    "              eval_set=(valid_data, train_y.loc[valid_index]), early_stopping_rounds=100,verbose=200)\n",
    "    prob[valid_index] = model.predict_proba(valid_data)[:, 1]\n",
    "    test_prob += model.predict_proba(test_data)[:, 1]/5\n",
    "    valid_score.append(model.best_score_['valid_0']['binary_logloss'])\n",
    "print('score:', np.mean(valid_score), valid_score)\n",
    "train['lgb_prob0'] = prob\n",
    "test['lgb_prob0'] = test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_training\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.15334\n",
      "Early stopping, best iteration is:\n",
      "[269]\tvalid_0's binary_logloss: 0.152507\n",
      "1_training\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.143252\n",
      "Early stopping, best iteration is:\n",
      "[329]\tvalid_0's binary_logloss: 0.139927\n",
      "2_training\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.14483\n",
      "Early stopping, best iteration is:\n",
      "[334]\tvalid_0's binary_logloss: 0.141436\n",
      "3_training\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.146651\n",
      "Early stopping, best iteration is:\n",
      "[307]\tvalid_0's binary_logloss: 0.143572\n",
      "4_training\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.143128\n",
      "[400]\tvalid_0's binary_logloss: 0.139877\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid_0's binary_logloss: 0.139798\n",
      "score: 0.14344795786703593 [0.15250664269190736, 0.13992660184927622, 0.14143574826633068, 0.14357240395378226, 0.13979839257388316]\n"
     ]
    }
   ],
   "source": [
    "# 使用lightgbm初训练获取预测结果用于后续stacking\n",
    "kf = StratifiedKFold(5,True,random_state=1)\n",
    "prob = np.zeros(len(train))\n",
    "test_prob = np.zeros(len(test))\n",
    "test_data = test[feat0].values\n",
    "valid_score = []\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(train, train_y)):\n",
    "    print(str(idx) + '_training')\n",
    "    train_data = train.loc[train_index][feat0].values\n",
    "    valid_data = train.loc[valid_index][feat0].values\n",
    "    model = LGBMClassifier(n_estimators=1000, learning_rate=0.01, num_leaves=31, \n",
    "                           subsample=0.8, colsample_bytree=0.6, n_jobs=-1, seed=4396)\n",
    "    model.fit(train_data, train_y.loc[train_index], \n",
    "              eval_set=(valid_data, train_y.loc[valid_index]), early_stopping_rounds=50,verbose=200)\n",
    "    prob[valid_index] = model.predict_proba(valid_data)[:, 1]\n",
    "    test_prob += model.predict_proba(test_data)[:, 1]/5\n",
    "    valid_score.append(model.best_score_['valid_0']['binary_logloss'])\n",
    "print('score:', np.mean(valid_score), valid_score)\n",
    "train['lgb_prob1'] = prob\n",
    "test['lgb_prob1'] = test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_training\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.148673\n",
      "[400]\tvalid_0's binary_logloss: 0.145208\n",
      "Early stopping, best iteration is:\n",
      "[382]\tvalid_0's binary_logloss: 0.145126\n",
      "1_training\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.142152\n",
      "[400]\tvalid_0's binary_logloss: 0.136975\n",
      "Early stopping, best iteration is:\n",
      "[407]\tvalid_0's binary_logloss: 0.136924\n",
      "2_training\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.143864\n",
      "[400]\tvalid_0's binary_logloss: 0.138256\n",
      "[600]\tvalid_0's binary_logloss: 0.137435\n",
      "Early stopping, best iteration is:\n",
      "[640]\tvalid_0's binary_logloss: 0.137304\n",
      "3_training\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.141455\n",
      "[400]\tvalid_0's binary_logloss: 0.136562\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's binary_logloss: 0.136397\n",
      "4_training\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.1397\n",
      "[400]\tvalid_0's binary_logloss: 0.134701\n",
      "Early stopping, best iteration is:\n",
      "[548]\tvalid_0's binary_logloss: 0.134417\n",
      "score: 0.1380333896070159 [0.1451257088560109, 0.13692406180356587, 0.13730389704966067, 0.13639675655124472, 0.13441652377459717]\n"
     ]
    }
   ],
   "source": [
    "# 使用lightgbm初训练获取预测结果用于后续stacking\n",
    "kf = StratifiedKFold(5,True,random_state=1)\n",
    "prob = np.zeros(len(train))\n",
    "test_prob = np.zeros(len(test))\n",
    "test_data = test[feat0].values\n",
    "valid_score = []\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(train, train_y)):\n",
    "    print(str(idx) + '_training')\n",
    "    train_data = train.loc[train_index][feat0].values\n",
    "    valid_data = train.loc[valid_index][feat0].values\n",
    "    model = LGBMClassifier(n_estimators=1000, learning_rate=0.01, num_leaves=7, \n",
    "                           subsample=0.8, colsample_bytree=0.6, n_jobs=4, seed=2020)\n",
    "    model.fit(train_data, train_y.loc[train_index], \n",
    "              eval_set=(valid_data, train_y.loc[valid_index]), early_stopping_rounds=50,verbose=200)\n",
    "    prob[valid_index] = model.predict_proba(valid_data)[:, 1]\n",
    "    test_prob += model.predict_proba(test_data)[:, 1]/5\n",
    "    valid_score.append(model.best_score_['valid_0']['binary_logloss'])\n",
    "print('score:', np.mean(valid_score), valid_score)\n",
    "train['lgb_prob2'] = prob\n",
    "test['lgb_prob2'] = test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "[0]\ttrain-logloss:0.67645\tvalid-logloss:0.67688\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[200]\ttrain-logloss:0.09196\tvalid-logloss:0.14794\n",
      "Stopping. Best iteration:\n",
      "[293]\ttrain-logloss:0.07662\tvalid-logloss:0.14557\n",
      "\n",
      "fold 2\n",
      "[0]\ttrain-logloss:0.67636\tvalid-logloss:0.67683\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[200]\ttrain-logloss:0.09293\tvalid-logloss:0.14697\n",
      "Stopping. Best iteration:\n",
      "[265]\ttrain-logloss:0.08036\tvalid-logloss:0.14458\n",
      "\n",
      "fold 3\n",
      "[0]\ttrain-logloss:0.67641\tvalid-logloss:0.67696\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[200]\ttrain-logloss:0.09143\tvalid-logloss:0.14907\n",
      "Stopping. Best iteration:\n",
      "[247]\ttrain-logloss:0.08126\tvalid-logloss:0.14671\n",
      "\n",
      "fold 4\n",
      "[0]\ttrain-logloss:0.67650\tvalid-logloss:0.67681\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[200]\ttrain-logloss:0.09419\tvalid-logloss:0.14283\n",
      "Stopping. Best iteration:\n",
      "[289]\ttrain-logloss:0.07971\tvalid-logloss:0.13876\n",
      "\n",
      "fold 5\n",
      "[0]\ttrain-logloss:0.67641\tvalid-logloss:0.67665\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[200]\ttrain-logloss:0.09274\tvalid-logloss:0.14429\n",
      "Stopping. Best iteration:\n",
      "[250]\ttrain-logloss:0.08192\tvalid-logloss:0.14295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # 使用xgb初训练获取预测结果用于后续stacking\n",
    "import xgboost as xgb\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'gamma': 0.1,\n",
    "    'max_depth': 8,\n",
    "    'alpha': 0,\n",
    "    'lambda': 0,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'min_child_weight': 3,\n",
    "    'silent': 1,\n",
    "    'eta': 0.02,\n",
    "    'nthread': 8,\n",
    "    'missing': 1,\n",
    "    'seed': 2019,\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "xgb_prob = np.zeros((test.shape[0]))\n",
    "prob = np.zeros(len(train))\n",
    "\n",
    "## train and predict\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train_y)):\n",
    "    print(\"fold {}\".format(fold_ + 1))\n",
    "    trn_data = xgb.DMatrix(train.iloc[trn_idx][feat0], label=train_y[trn_idx])\n",
    "    val_data = xgb.DMatrix(train.iloc[val_idx][feat0], label=train_y[val_idx])\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n",
    "    \n",
    "    clf = xgb.train(params, trn_data,  5000, watchlist, verbose_eval=200, early_stopping_rounds=50)\n",
    "    xgb_prob += clf.predict(xgb.DMatrix(test[feat0]), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    prob[val_idx] = clf.predict(xgb.DMatrix(train.iloc[val_idx][feat0]), ntree_limit=clf.best_ntree_limit)\n",
    "\n",
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"Feature\"] = clf.get_fscore().keys()\n",
    "fold_importance_df[\"importance\"] = clf.get_fscore().values()\n",
    "fold_importance_df[\"fold\"] = fold_ + 1\n",
    "feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "train['xgb_prob'] = prob\n",
    "test['xgb_prob'] = xgb_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_training\n",
      "0:\tlearn: 0.6565801\ttest: 0.6563305\tbest: 0.6563305 (0)\ttotal: 359ms\tremaining: 5m 58s\n",
      "200:\tlearn: 0.1216963\ttest: 0.1328158\tbest: 0.1328158 (200)\ttotal: 32.6s\tremaining: 2m 9s\n",
      "400:\tlearn: 0.1066960\ttest: 0.1312358\tbest: 0.1312318 (398)\ttotal: 1m 3s\tremaining: 1m 35s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1311706221\n",
      "bestIteration = 423\n",
      "\n",
      "Shrink model to first 424 iterations.\n",
      "1_training\n",
      "0:\tlearn: 0.6579619\ttest: 0.6579634\tbest: 0.6579634 (0)\ttotal: 167ms\tremaining: 2m 46s\n",
      "200:\tlearn: 0.1172104\ttest: 0.1430811\tbest: 0.1430811 (200)\ttotal: 31.5s\tremaining: 2m 5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1429972266\n",
      "bestIteration = 204\n",
      "\n",
      "Shrink model to first 205 iterations.\n",
      "2_training\n",
      "0:\tlearn: 0.6542509\ttest: 0.6548254\tbest: 0.6548254 (0)\ttotal: 176ms\tremaining: 2m 55s\n",
      "200:\tlearn: 0.1178167\ttest: 0.1511827\tbest: 0.1511150 (198)\ttotal: 32.6s\tremaining: 2m 9s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1510175981\n",
      "bestIteration = 219\n",
      "\n",
      "Shrink model to first 220 iterations.\n",
      "3_training\n",
      "0:\tlearn: 0.6563835\ttest: 0.6564572\tbest: 0.6564572 (0)\ttotal: 174ms\tremaining: 2m 54s\n",
      "200:\tlearn: 0.1212184\ttest: 0.1376961\tbest: 0.1376961 (200)\ttotal: 32.3s\tremaining: 2m 8s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1372224602\n",
      "bestIteration = 303\n",
      "\n",
      "Shrink model to first 304 iterations.\n",
      "4_training\n",
      "0:\tlearn: 0.6585353\ttest: 0.6582392\tbest: 0.6582392 (0)\ttotal: 182ms\tremaining: 3m 2s\n",
      "200:\tlearn: 0.1182574\ttest: 0.1389833\tbest: 0.1389525 (198)\ttotal: 34.4s\tremaining: 2m 16s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1389525002\n",
      "bestIteration = 198\n",
      "\n",
      "Shrink model to first 199 iterations.\n",
      "score: [{'learn': {'Logloss': 0.1014329112233555}, 'validation': {'Logloss': 0.13117062208611127}}, {'learn': {'Logloss': 0.11164649684388978}, 'validation': {'Logloss': 0.14299722659487665}}, {'learn': {'Logloss': 0.11105922622749669}, 'validation': {'Logloss': 0.15101759805399134}}, {'learn': {'Logloss': 0.10866567823271217}, 'validation': {'Logloss': 0.13722246018006393}}, {'learn': {'Logloss': 0.11293629572829347}, 'validation': {'Logloss': 0.13895250018901853}}]\n"
     ]
    }
   ],
   "source": [
    "# # 使用catboost初训练获取预测结果用于后续stacking\n",
    "kf = StratifiedKFold(5, True, random_state=1)\n",
    "prob = np.zeros(len(train))\n",
    "cat_prob = np.zeros(len(test))\n",
    "feat1=list(set(feat0))\n",
    "test_data=test[feat1].values\n",
    "valid_score = []\n",
    "\n",
    "for idx, (train_index, valid_index) in enumerate(kf.split(train, train_y)):\n",
    "    print(str(idx)+'_training')\n",
    "    train_data = train.loc[train_index][feat1]\n",
    "    valid_data = train.loc[valid_index][feat1]\n",
    "    model = CatBoostClassifier(iterations=1000, learning_rate=0.02, depth=7,thread_count=8)\n",
    "    model.fit(train_data, train_y.loc[train_index], \n",
    "              eval_set=(valid_data, train_y.loc[valid_index]), early_stopping_rounds=50,verbose=200)\n",
    "    prob[valid_index] = model.predict_proba(valid_data)[:, 1]\n",
    "    cat_prob += model.predict_proba(test_data)[:,1]/5\n",
    "    valid_score.append(model.best_score_)\n",
    "print('score:', valid_score)\n",
    "\n",
    "train['cat_prob'] = prob\n",
    "test['cat_prob'] = cat_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train _K_ flod 0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\ttrain's binary_logloss: 0.137715\tvalid's binary_logloss: 0.137893\n",
      "[400]\ttrain's binary_logloss: 0.127203\tvalid's binary_logloss: 0.133149\n",
      "Early stopping, best iteration is:\n",
      "[489]\ttrain's binary_logloss: 0.124369\tvalid's binary_logloss: 0.132863\n",
      "train _K_ flod 1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\ttrain's binary_logloss: 0.135405\tvalid's binary_logloss: 0.14637\n",
      "[400]\ttrain's binary_logloss: 0.124658\tvalid's binary_logloss: 0.143034\n",
      "Early stopping, best iteration is:\n",
      "[373]\ttrain's binary_logloss: 0.125619\tvalid's binary_logloss: 0.142966\n",
      "train _K_ flod 2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\ttrain's binary_logloss: 0.13794\tvalid's binary_logloss: 0.138312\n",
      "[400]\ttrain's binary_logloss: 0.127299\tvalid's binary_logloss: 0.132453\n",
      "Early stopping, best iteration is:\n",
      "[462]\ttrain's binary_logloss: 0.125207\tvalid's binary_logloss: 0.132148\n",
      "train _K_ flod 3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\ttrain's binary_logloss: 0.133834\tvalid's binary_logloss: 0.149291\n",
      "[400]\ttrain's binary_logloss: 0.123223\tvalid's binary_logloss: 0.145402\n",
      "Early stopping, best iteration is:\n",
      "[413]\ttrain's binary_logloss: 0.122792\tvalid's binary_logloss: 0.145386\n",
      "train _K_ flod 4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[200]\ttrain's binary_logloss: 0.136271\tvalid's binary_logloss: 0.141033\n",
      "[400]\ttrain's binary_logloss: 0.12583\tvalid's binary_logloss: 0.136138\n",
      "Early stopping, best iteration is:\n",
      "[507]\ttrain's binary_logloss: 0.122233\tvalid's binary_logloss: 0.135828\n",
      "score: 0.13783839967433323 [0.13286324852075385, 0.14296639011397927, 0.13214834666491404, 0.14538637207181412, 0.13582764100020484]\n"
     ]
    }
   ],
   "source": [
    "# 使用上述模型预测结果、model1预测结果和全部特征进行训练，获取最终结果\n",
    "# 使用lgb，在构建lgb.dataset时加入预设置的权重，降低分布不一致的训练数据的影响，降低过拟合\n",
    "# 使用不同模式的lightgbm预测结果作为stacking特征效果会更好\n",
    "# 加权融合的效果不好\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_code2 = pd.read_csv('./output/train_stacking_code2_1.csv')\n",
    "test_code2 = pd.read_csv('./output/test_stacking_code2_1.csv')\n",
    "train = train.merge(train_code2, on='ID', how='left')\n",
    "test = test.merge(test_code2, on='ID', how='left')\n",
    "\n",
    "feat=list(set(feat0 + ['lgb_prob0', 'lgb_prob1','lgb_prob2','xgb_prob', 'cat_prob',\n",
    "                       'code2_lgb_prob1']))\n",
    "\n",
    "prob = np.zeros(len(train))\n",
    "test_prob = np.zeros(len(test))\n",
    "test_data = test[feat0].values\n",
    "valid_score = []\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1024, shuffle=True)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_seed':0,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 1,\n",
    "    'reg_alpha':3,\n",
    "    'reg_lambda':1\n",
    "}\n",
    "\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train, train_y)):\n",
    "    print('train _K_ flod', k)\n",
    "    \n",
    "    lgb_train = lgb.Dataset(train.iloc[train_index][feat].values, train_y[train_index], weight=train.iloc[train_index]['weight'].values)\n",
    "    lgb_evals = lgb.Dataset(train.iloc[test_index][feat].values, train_y[test_index], reference=lgb_train)\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=5000,\n",
    "                    valid_sets=[lgb_train,lgb_evals],\n",
    "                    valid_names=['train','valid'],\n",
    "                    early_stopping_rounds=50,\n",
    "                    verbose_eval=200,\n",
    "                    )\n",
    "    prob[test_index] = model.predict(train.iloc[test_index][feat].values, num_iteration=model.best_iteration)\n",
    "    test_prob += model.predict(test_data, num_iteration=model.best_iteration)/5\n",
    "    valid_score.append(model.best_score['valid']['binary_logloss'])\n",
    "print('score:', np.mean(valid_score), valid_score)\n",
    "train['lgb_prob_new'] = prob\n",
    "test['lgb_prob_new'] = test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('./data/test_stage2_update_20200320.csv')\n",
    "test_df['Label'] = test['lgb_prob_new']\n",
    "test_df[['ID', 'Label']].to_csv('./output/sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
